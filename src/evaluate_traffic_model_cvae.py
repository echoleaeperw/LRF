#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
STRIVE CVAE è´¨é‡è¯„ä¼°è„šæœ¬ - ç›´æ¥ä½¿ç”¨ traffic_model.pth
ä½¿ç”¨ traffic_model.pth åœ¨ nuScenes æ•°æ®é›†ä¸Šç”Ÿæˆé¢„æµ‹è½¨è¿¹ï¼Œå¹¶ä¸çœŸå®æœªæ¥è½¨è¿¹å¯¹æ¯”
éªŒè¯ä¸¤ä¸ªå…³é”®æŒ‡æ ‡ï¼š
1. è½¨è¿¹é‡å»º MSE < 0.05 mÂ²
2. åŠ é€Ÿåº¦å’Œæ›²ç‡åˆ†å¸ƒ KL æ•£åº¦ < 0.5

åŒæ—¶è®¡ç®—æ ‡å‡†è½¨è¿¹è¯„ä¼°æŒ‡æ ‡ï¼š
- ADE (Average Displacement Error): å¹³å‡ä½ç§»è¯¯å·®
- FDE (Final Displacement Error): æœ€ç»ˆä½ç§»è¯¯å·®
- MR@2m (Miss Rate): æœªå‘½ä¸­ç‡
"""

import os
import sys
import argparse
from pathlib import Path
import torch
import numpy as np
from torch_geometric.data import DataLoader as GraphDataLoader
import time
from typing import Optional, Dict, List, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__))
sys.path.insert(0, os.path.join(project_root, 'src'))

from models.traffic_model import TrafficModel
from datasets.nuscenes_dataset import NuScenesDataset
from datasets.map_env import NuScenesMapEnv
from utils.torch import get_device, load_state, count_params
from utils.common import dict2obj
from utils.logger import Logger
from rich.console import Console
from rich.panel import Panel
from rich.progress import track, Progress
from rich.table import Table

console = Console()


class CVAEModelEvaluator:
    """ç›´æ¥è¯„ä¼° CVAE æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„é‡å»ºè´¨é‡"""
    
    def __init__(self, model, test_dataset, map_env, device, 
                 max_mse_threshold=0.05, max_kl_divergence=0.5, 
                 filter_outliers=True, outlier_iqr_factor=1.5):
        self.model = model
        self.test_dataset = test_dataset
        self.map_env = map_env
        self.device = device
        self.max_mse_threshold = max_mse_threshold
        self.max_kl_divergence = max_kl_divergence
        self.filter_outliers = filter_outliers
        self.outlier_iqr_factor = outlier_iqr_factor
        
        self.model.eval()
    
    def remove_outliers_iqr(self, data, factor=1.5):
        """ä½¿ç”¨ IQR æ–¹æ³•ç§»é™¤å¼‚å¸¸å€¼"""
        if len(data) < 4:  # æ•°æ®å¤ªå°‘æ— æ³•è®¡ç®—å››åˆ†ä½æ•°
            return data, []
        
        data_array = np.array(data)
        Q1 = np.percentile(data_array, 25)
        Q3 = np.percentile(data_array, 75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        # æ ‡è®°å¼‚å¸¸å€¼
        outlier_mask = (data_array < lower_bound) | (data_array > upper_bound)
        outliers = data_array[outlier_mask]
        filtered_data = data_array[~outlier_mask]
        
        return filtered_data.tolist(), outliers.tolist()
        
    def calculate_trajectory_mse(self, pred_traj, gt_traj, valid_mask=None):
        """è®¡ç®—è½¨è¿¹å‡æ–¹è¯¯å·®ï¼Œåªè®¡ç®—æœ‰æ•ˆç‚¹"""
        # pred_traj: [NA, FT, 4+]
        # gt_traj: [NA, FT, 6]
        # valid_mask: [NA, FT] å¯è§æ€§æ©ç 
        
        # åªæ¯”è¾ƒä½ç½® (x, y)
        pred_pos = pred_traj[:, :, :2]  # [NA, FT, 2]
        gt_pos = gt_traj[:, :, :2]      # [NA, FT, 2]
        
        # å¦‚æœæœ‰ valid_maskï¼Œåªè®¡ç®—å¯è§ç‚¹
        if valid_mask is not None:
            # æ‰©å±• mask åˆ°ä½ç½®ç»´åº¦ [NA, FT, 2]
            mask_expanded = valid_mask.unsqueeze(-1).expand_as(pred_pos)
            pred_pos_valid = pred_pos[mask_expanded].view(-1, 2)
            gt_pos_valid = gt_pos[mask_expanded].view(-1, 2)
            
            if pred_pos_valid.numel() == 0:
                return float('nan')
            
            # è®¡ç®—æ¬§æ°è·ç¦»å¹³æ–¹
            mse = torch.mean((pred_pos_valid - gt_pos_valid) ** 2).item()
        else:
            # è¿‡æ»¤æ‰ NaN å€¼
            valid = ~torch.isnan(gt_pos).any(dim=-1)  # [NA, FT]
            if valid.sum() == 0:
                return float('nan')
            
            mask_expanded = valid.unsqueeze(-1).expand_as(pred_pos)
            pred_pos_valid = pred_pos[mask_expanded].view(-1, 2)
            gt_pos_valid = gt_pos[mask_expanded].view(-1, 2)
            
            mse = torch.mean((pred_pos_valid - gt_pos_valid) ** 2).item()
        
        return mse
    
    def calculate_ade(self, pred_traj: torch.Tensor, gt_traj: torch.Tensor, valid_mask: Optional[torch.Tensor] = None) -> float:
        """è®¡ç®—å¹³å‡ä½ç§»è¯¯å·® (Average Displacement Error, ADE)"""
        # pred_traj: [NA, FT, 4+]
        # gt_traj: [NA, FT, 6]
        # valid_mask: [NA, FT] å¯è§æ€§æ©ç 
        
        # åªæ¯”è¾ƒä½ç½® (x, y)
        pred_pos = pred_traj[:, :, :2]  # [NA, FT, 2]
        gt_pos = gt_traj[:, :, :2]      # [NA, FT, 2]
        
        # è®¡ç®—æ¬§æ°è·ç¦»
        displacement = torch.norm(pred_pos - gt_pos, dim=-1)  # [NA, FT]
        
        # åº”ç”¨æœ‰æ•ˆæ©ç 
        if valid_mask is not None:
            displacement = displacement * valid_mask
            num_valid = valid_mask.sum()
            if num_valid == 0:
                return float('nan')
        else:
            # è¿‡æ»¤ NaN å€¼
            valid = ~torch.isnan(displacement)
            displacement = displacement[valid]
            num_valid = valid.sum()
            if num_valid == 0:
                return float('nan')
        
        # è®¡ç®—å¹³å‡å€¼
        ade = displacement.sum() / num_valid
        return ade.item()
    
    def calculate_fde(self, pred_traj: torch.Tensor, gt_traj: torch.Tensor, valid_mask: Optional[torch.Tensor] = None) -> float:
        """è®¡ç®—æœ€ç»ˆä½ç§»è¯¯å·® (Final Displacement Error, FDE)"""
        # pred_traj: [NA, FT, 4+]
        # gt_traj: [NA, FT, 6]
        # valid_mask: [NA, FT] å¯è§æ€§æ©ç 
        
        # åªæ¯”è¾ƒä½ç½® (x, y)
        pred_pos = pred_traj[:, :, :2]  # [NA, FT, 2]
        gt_pos = gt_traj[:, :, :2]      # [NA, FT, 2]
        
        batch_size = pred_pos.size(0)
        fde_list = []
        
        for i in range(batch_size):
            # æ‰¾åˆ°æ¯ä¸ªè½¨è¿¹çš„æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥
            if valid_mask is not None:
                valid_indices = torch.where(valid_mask[i])[0]
                if len(valid_indices) == 0:
                    continue
                last_idx = valid_indices[-1]
            else:
                # æ‰¾åˆ°é NaN çš„æœ€åä¸€ä¸ªç‚¹
                valid_indices = torch.where(~torch.isnan(gt_pos[i, :, 0]))[0]
                if len(valid_indices) == 0:
                    continue
                last_idx = valid_indices[-1]
            
            # è®¡ç®—æœ€åä¸€ä¸ªç‚¹çš„æ¬§æ°è·ç¦»
            final_displacement = torch.norm(pred_pos[i, last_idx] - gt_pos[i, last_idx])
            fde_list.append(final_displacement.item())
        
        if len(fde_list) == 0:
            return float('nan')
        
        return np.mean(fde_list)
    
    def calculate_miss_rate(self, pred_traj: torch.Tensor, gt_traj: torch.Tensor, 
                           miss_threshold: float = 2.0, valid_mask: Optional[torch.Tensor] = None) -> float:
        """è®¡ç®—æœªå‘½ä¸­ç‡ (Miss Rate)"""
        # pred_traj: [NA, FT, 4+]
        # gt_traj: [NA, FT, 6]
        # valid_mask: [NA, FT] å¯è§æ€§æ©ç 
        
        # åªæ¯”è¾ƒä½ç½® (x, y)
        pred_pos = pred_traj[:, :, :2]  # [NA, FT, 2]
        gt_pos = gt_traj[:, :, :2]      # [NA, FT, 2]
        
        batch_size = pred_pos.size(0)
        miss_count = 0
        
        for i in range(batch_size):
            # è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„ä½ç§»
            displacement = torch.norm(pred_pos[i] - gt_pos[i], dim=-1)
            
            # åº”ç”¨æœ‰æ•ˆæ©ç 
            if valid_mask is not None:
                displacement = displacement[valid_mask[i]]
            else:
                valid = ~torch.isnan(displacement)
                displacement = displacement[valid]
            
            if len(displacement) == 0:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ—¶é—´æ­¥è¶…è¿‡é˜ˆå€¼
            if (displacement > miss_threshold).any():
                miss_count += 1
        
        return miss_count / batch_size if batch_size > 0 else 0.0
    
    def calculate_acceleration(self, trajectory, dt=0.5):
        """è®¡ç®—åŠ é€Ÿåº¦åºåˆ—ï¼Œè¿‡æ»¤ NaN å€¼"""
        # trajectory: [NA, FT, 4+]
        positions = trajectory[:, :, :2]  # [NA, FT, 2]
        
        # è¿‡æ»¤æ‰åŒ…å« NaN çš„è½¨è¿¹
        valid_mask = ~torch.isnan(positions).any(dim=-1)  # [NA, FT]
        
        accelerations_list = []
        for agent_idx in range(positions.size(0)):
            agent_pos = positions[agent_idx][valid_mask[agent_idx]]  # [T_valid, 2]
            
            if len(agent_pos) < 3:  # éœ€è¦è‡³å°‘3ä¸ªç‚¹æ‰èƒ½è®¡ç®—åŠ é€Ÿåº¦
                continue
            
            # è®¡ç®—é€Ÿåº¦
            velocities = torch.diff(agent_pos, dim=0) / dt  # [T-1, 2]
            
            # è®¡ç®—åŠ é€Ÿåº¦
            accelerations = torch.diff(velocities, dim=0) / dt  # [T-2, 2]
            
            # åŠ é€Ÿåº¦å¤§å°
            acc_magnitude = torch.norm(accelerations, dim=-1)  # [T-2]
            accelerations_list.append(acc_magnitude.cpu().numpy())
        
        if len(accelerations_list) == 0:
            return np.array([])
        
        return np.concatenate(accelerations_list)
    
    def calculate_curvature(self, trajectory, dt=0.5):
        """è®¡ç®—æ›²ç‡åºåˆ—ï¼Œè¿‡æ»¤ NaN å€¼"""
        # trajectory: [NA, FT, 4+]
        positions = trajectory[:, :, :2].cpu().numpy()  # [NA, FT, 2]
        
        curvatures = []
        for agent_traj in positions:
            # è¿‡æ»¤æ‰ NaN å€¼
            valid_idx = ~np.isnan(agent_traj).any(axis=1)
            agent_traj_valid = agent_traj[valid_idx]
            
            # å¯¹æ¯ä¸ªæ™ºèƒ½ä½“çš„è½¨è¿¹è®¡ç®—æ›²ç‡
            if len(agent_traj_valid) < 3:
                continue
                
            dx = np.gradient(agent_traj_valid[:, 0])
            dy = np.gradient(agent_traj_valid[:, 1])
            ddx = np.gradient(dx)
            ddy = np.gradient(dy)
            
            numerator = np.abs(dx * ddy - dy * ddx)
            denominator = np.power(dx**2 + dy**2, 1.5)
            denominator = np.where(denominator < 1e-8, 1e-8, denominator)
            
            curvature = numerator / denominator
            
            # è¿‡æ»¤æ‰æ— æ•ˆæ›²ç‡å€¼
            valid_curvature = curvature[1:-1]  # å»é™¤è¾¹ç•Œç‚¹
            valid_curvature = valid_curvature[~np.isnan(valid_curvature)]
            valid_curvature = valid_curvature[~np.isinf(valid_curvature)]
            
            curvatures.extend(valid_curvature)
        
        return np.array(curvatures)
    
    def calculate_kl_divergence(self, dist1, dist2, bins=50):
        """è®¡ç®— KL æ•£åº¦ï¼Œå¤„ç† NaN å’Œ Inf"""
        # è¿‡æ»¤æ‰æ— æ•ˆå€¼
        dist1 = dist1[~np.isnan(dist1)]
        dist1 = dist1[~np.isinf(dist1)]
        dist2 = dist2[~np.isnan(dist2)]
        dist2 = dist2[~np.isinf(dist2)]
        
        if len(dist1) == 0 or len(dist2) == 0:
            return float('nan')
        
        if len(dist1) < 10 or len(dist2) < 10:  # æ ·æœ¬å¤ªå°‘
            return float('nan')
        
        min_val = min(np.min(dist1), np.min(dist2))
        max_val = max(np.max(dist1), np.max(dist2))
        
        if max_val <= min_val or np.isnan(min_val) or np.isnan(max_val):
            return float('nan')
        
        hist1, _ = np.histogram(dist1, bins=bins, range=(min_val, max_val), density=True)
        hist2, _ = np.histogram(dist2, bins=bins, range=(min_val, max_val), density=True)
        
        # å½’ä¸€åŒ–
        sum1 = np.sum(hist1)
        sum2 = np.sum(hist2)
        
        if sum1 <= 1e-10 or sum2 <= 1e-10:
            return float('nan')
        
        hist1 = hist1 / sum1
        hist2 = hist2 / sum2
        
        # æ·»åŠ å¹³æ»‘é¡¹é¿å… log(0)
        epsilon = 1e-10
        hist1 = hist1 + epsilon
        hist2 = hist2 + epsilon
        
        # é‡æ–°å½’ä¸€åŒ–
        hist1 = hist1 / np.sum(hist1)
        hist2 = hist2 / np.sum(hist2)
        
        # è®¡ç®— KL æ•£åº¦
        kl_div = np.sum(hist1 * np.log(hist1 / hist2))
        
        # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
        if np.isnan(kl_div) or np.isinf(kl_div):
            return float('nan')
        
        return kl_div
    
    def evaluate_batch(self, scene_graph, map_idx):
        """è¯„ä¼°ä¸€ä¸ªæ‰¹æ¬¡"""
        with torch.no_grad():
            # ä½¿ç”¨åéªŒå‡å€¼è¿›è¡Œé‡å»ºï¼ˆè¿™æ˜¯CVAEçš„æ ‡å‡†è¯„ä¼°æ–¹å¼ï¼‰
            pred = self.model(scene_graph, map_idx, self.map_env, use_post_mean=True)
            future_pred = pred['future_pred']  # [NA, FT, 4]
            future_gt = scene_graph.future_gt  # [NA, FT, 6]
            future_vis = scene_graph.future_vis  # [NA, FT]
            
            # åå½’ä¸€åŒ–
            normalizer = self.model.get_normalizer()
            future_pred_unnorm = normalizer.unnormalize(future_pred)
            future_gt_unnorm = normalizer.unnormalize(future_gt)
            
            # åªè¯„ä¼°å¯è§çš„æ—¶é—´æ­¥
            valid_mask = future_vis == 1.0
            if valid_mask.sum() == 0:
                return None
            
            # è®¡ç®— MSEï¼ˆä½¿ç”¨ valid_maskï¼‰
            mse = self.calculate_trajectory_mse(future_pred_unnorm, future_gt_unnorm, valid_mask)
            
            # è®¡ç®—æ ‡å‡†è½¨è¿¹è¯„ä¼°æŒ‡æ ‡
            ade = self.calculate_ade(future_pred_unnorm, future_gt_unnorm, valid_mask)
            fde = self.calculate_fde(future_pred_unnorm, future_gt_unnorm, valid_mask)
            mr_2m = self.calculate_miss_rate(future_pred_unnorm, future_gt_unnorm, miss_threshold=2.0, valid_mask=valid_mask)
            
            # è®¡ç®—åŠ é€Ÿåº¦
            pred_acc = self.calculate_acceleration(future_pred_unnorm)
            gt_acc = self.calculate_acceleration(future_gt_unnorm)
            
            # è®¡ç®—æ›²ç‡
            pred_curv = self.calculate_curvature(future_pred_unnorm)
            gt_curv = self.calculate_curvature(future_gt_unnorm)
            
            # è®¡ç®— KL æ•£åº¦
            acc_kl = self.calculate_kl_divergence(pred_acc, gt_acc) if len(pred_acc) > 0 and len(gt_acc) > 0 else float('nan')
            curv_kl = self.calculate_kl_divergence(pred_curv, gt_curv) if len(pred_curv) > 0 and len(gt_curv) > 0 else float('nan')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæŒ‡æ ‡
            if np.isnan(mse) and np.isnan(acc_kl) and np.isnan(curv_kl) and np.isnan(ade):
                return None
            
            return {
                'mse': mse,
                'ade': ade,
                'fde': fde,
                'mr_2m': mr_2m,
                'acc_kl': acc_kl,
                'curv_kl': curv_kl,
                'num_agents': future_pred.size(0),
                'num_timesteps': future_pred.size(1)
            }
    
    def evaluate_dataset(self, num_samples=None):
        """åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°"""
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        test_loader = GraphDataLoader(
            self.test_dataset,
            batch_size=1,
            shuffle=False,
            num_workers=0,
            pin_memory=False
        )
        
        all_metrics = {
            'mse': [],
            'ade': [],
            'fde': [],
            'mr_2m': [],
            'acc_kl': [],
            'curv_kl': []
        }
        
        # å­˜å‚¨æ¯ä¸ªåœºæ™¯çš„è¯¦ç»†ç»“æœ
        scene_details = []
        
        total_scenes = num_samples if num_samples else len(test_loader)
        console.print(f"\n[cyan]å¼€å§‹è¯„ä¼° CVAE æ¨¡å‹åœ¨ nuScenes æ•°æ®é›†ä¸Šçš„é‡å»ºè´¨é‡...[/cyan]")
        console.print(f"[dim]è¯„ä¼°åœºæ™¯æ•°: {total_scenes}[/dim]\n")
        
        with Progress() as progress:
            task = progress.add_task("[cyan]è¯„ä¼°ä¸­...", total=total_scenes)
            
            for i, data in enumerate(test_loader):
                if num_samples and i >= num_samples:
                    break
                
                scene_graph, map_idx = data
                scene_graph = scene_graph.to(self.device)
                map_idx = map_idx.to(self.device)
                
                try:
                    batch_result = self.evaluate_batch(scene_graph, map_idx)
                    
                    if batch_result is not None:
                        # åªæ·»åŠ æœ‰æ•ˆçš„æŒ‡æ ‡
                        if not np.isnan(batch_result['mse']):
                            all_metrics['mse'].append(batch_result['mse'])
                        if not np.isnan(batch_result['ade']):
                            all_metrics['ade'].append(batch_result['ade'])
                        if not np.isnan(batch_result['fde']):
                            all_metrics['fde'].append(batch_result['fde'])
                        if not np.isnan(batch_result['mr_2m']):
                            all_metrics['mr_2m'].append(batch_result['mr_2m'])
                        if not np.isnan(batch_result['acc_kl']):
                            all_metrics['acc_kl'].append(batch_result['acc_kl'])
                        if not np.isnan(batch_result['curv_kl']):
                            all_metrics['curv_kl'].append(batch_result['curv_kl'])
                        
                        # è®°å½•è¯¦ç»†ä¿¡æ¯
                        scene_details.append({
                            'scene_id': i,
                            'num_agents': batch_result['num_agents'],
                            'num_timesteps': batch_result['num_timesteps'],
                            'mse': batch_result['mse'] if not np.isnan(batch_result['mse']) else None,
                            'ade': batch_result['ade'] if not np.isnan(batch_result['ade']) else None,
                            'fde': batch_result['fde'] if not np.isnan(batch_result['fde']) else None,
                            'mr_2m': batch_result['mr_2m'] if not np.isnan(batch_result['mr_2m']) else None,
                            'acc_kl': batch_result['acc_kl'] if not np.isnan(batch_result['acc_kl']) else None,
                            'curv_kl': batch_result['curv_kl'] if not np.isnan(batch_result['curv_kl']) else None,
                            'mse_pass': batch_result['mse'] <= self.max_mse_threshold if not np.isnan(batch_result['mse']) else False,
                            'kl_pass': (batch_result['acc_kl'] <= self.max_kl_divergence and 
                                       batch_result['curv_kl'] <= self.max_kl_divergence) if (
                                not np.isnan(batch_result['acc_kl']) and not np.isnan(batch_result['curv_kl'])) else False
                        })
                        
                except Exception as e:
                    console.print(f"[yellow]åœºæ™¯ {i} è¯„ä¼°å¤±è´¥: {e}[/yellow]")
                    scene_details.append({
                        'scene_id': i,
                        'num_agents': 0,
                        'num_timesteps': 0,
                        'mse': None,
                        'acc_kl': None,
                        'curv_kl': None,
                        'mse_pass': False,
                        'kl_pass': False,
                        'error': str(e)
                    })
                    continue
                
                progress.update(task, advance=1)
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        if len(all_metrics['mse']) == 0:
            console.print("[red]é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°ç»“æœ[/red]")
            return {
                'avg_mse': float('nan'),
                'std_mse': float('nan'),
                'avg_acc_kl': float('nan'),
                'std_acc_kl': float('nan'),
                'avg_curv_kl': float('nan'),
                'std_curv_kl': float('nan'),
                'mse_pass_rate': 0.0,
                'kl_pass_rate': 0.0,
                'total_scenes': 0
            }
        
        # è¿‡æ»¤å¼‚å¸¸å€¼
        filtered_metrics = {
            'mse': all_metrics['mse'].copy(),
            'ade': all_metrics['ade'].copy(),
            'fde': all_metrics['fde'].copy(),
            'mr_2m': all_metrics['mr_2m'].copy(),
            'acc_kl': all_metrics['acc_kl'].copy(),
            'curv_kl': all_metrics['curv_kl'].copy()
        }
        
        outlier_info = {}
        
        if self.filter_outliers:
            console.print(f"\n[cyan]æ£€æµ‹å¹¶è¿‡æ»¤å¼‚å¸¸å€¼ (IQR å› å­: {self.outlier_iqr_factor})...[/cyan]")
            
            # è¿‡æ»¤ MSE å¼‚å¸¸å€¼
            if len(all_metrics['mse']) > 0:
                filtered_mse, mse_outliers = self.remove_outliers_iqr(
                    all_metrics['mse'], self.outlier_iqr_factor
                )
                filtered_metrics['mse'] = filtered_mse
                outlier_info['mse_outliers'] = mse_outliers
                outlier_info['mse_outlier_count'] = len(mse_outliers)
                console.print(f"  MSE: ç§»é™¤ {len(mse_outliers)} ä¸ªå¼‚å¸¸å€¼ "
                            f"({len(mse_outliers)}/{len(all_metrics['mse'])} = "
                            f"{100*len(mse_outliers)/len(all_metrics['mse']):.1f}%)")
            
            # è¿‡æ»¤ ADE å¼‚å¸¸å€¼
            if len(all_metrics['ade']) > 0:
                filtered_ade, ade_outliers = self.remove_outliers_iqr(
                    all_metrics['ade'], self.outlier_iqr_factor
                )
                filtered_metrics['ade'] = filtered_ade
                outlier_info['ade_outliers'] = ade_outliers
                outlier_info['ade_outlier_count'] = len(ade_outliers)
                console.print(f"  ADE: ç§»é™¤ {len(ade_outliers)} ä¸ªå¼‚å¸¸å€¼ "
                            f"({len(ade_outliers)}/{len(all_metrics['ade'])} = "
                            f"{100*len(ade_outliers)/len(all_metrics['ade']):.1f}%)")
            
            # è¿‡æ»¤ FDE å¼‚å¸¸å€¼
            if len(all_metrics['fde']) > 0:
                filtered_fde, fde_outliers = self.remove_outliers_iqr(
                    all_metrics['fde'], self.outlier_iqr_factor
                )
                filtered_metrics['fde'] = filtered_fde
                outlier_info['fde_outliers'] = fde_outliers
                outlier_info['fde_outlier_count'] = len(fde_outliers)
                console.print(f"  FDE: ç§»é™¤ {len(fde_outliers)} ä¸ªå¼‚å¸¸å€¼ "
                            f"({len(fde_outliers)}/{len(all_metrics['fde'])} = "
                            f"{100*len(fde_outliers)/len(all_metrics['fde']):.1f}%)")
            
            # è¿‡æ»¤åŠ é€Ÿåº¦ KL å¼‚å¸¸å€¼
            if len(all_metrics['acc_kl']) > 0:
                filtered_acc_kl, acc_kl_outliers = self.remove_outliers_iqr(
                    all_metrics['acc_kl'], self.outlier_iqr_factor
                )
                filtered_metrics['acc_kl'] = filtered_acc_kl
                outlier_info['acc_kl_outliers'] = acc_kl_outliers
                outlier_info['acc_kl_outlier_count'] = len(acc_kl_outliers)
                console.print(f"  åŠ é€Ÿåº¦ KL: ç§»é™¤ {len(acc_kl_outliers)} ä¸ªå¼‚å¸¸å€¼ "
                            f"({len(acc_kl_outliers)}/{len(all_metrics['acc_kl'])} = "
                            f"{100*len(acc_kl_outliers)/len(all_metrics['acc_kl']):.1f}%)")
            
            # è¿‡æ»¤æ›²ç‡ KL å¼‚å¸¸å€¼
            if len(all_metrics['curv_kl']) > 0:
                filtered_curv_kl, curv_kl_outliers = self.remove_outliers_iqr(
                    all_metrics['curv_kl'], self.outlier_iqr_factor
                )
                filtered_metrics['curv_kl'] = filtered_curv_kl
                outlier_info['curv_kl_outliers'] = curv_kl_outliers
                outlier_info['curv_kl_outlier_count'] = len(curv_kl_outliers)
                console.print(f"  æ›²ç‡ KL: ç§»é™¤ {len(curv_kl_outliers)} ä¸ªå¼‚å¸¸å€¼ "
                            f"({len(curv_kl_outliers)}/{len(all_metrics['curv_kl'])} = "
                            f"{100*len(curv_kl_outliers)/len(all_metrics['curv_kl']):.1f}%)")
        
        results = {
            # åŸå§‹æ•°æ®ç»Ÿè®¡ï¼ˆåŒ…å«å¼‚å¸¸å€¼ï¼‰
            'raw_avg_mse': np.mean(all_metrics['mse']) if len(all_metrics['mse']) > 0 else float('nan'),
            'raw_avg_ade': np.mean(all_metrics['ade']) if len(all_metrics['ade']) > 0 else float('nan'),
            'raw_avg_acc_kl': np.mean(all_metrics['acc_kl']) if len(all_metrics['acc_kl']) > 0 else float('nan'),
            'raw_avg_curv_kl': np.mean(all_metrics['curv_kl']) if len(all_metrics['curv_kl']) > 0 else float('nan'),
            
            # è¿‡æ»¤åçš„ç»Ÿè®¡ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
            'avg_mse': np.mean(filtered_metrics['mse']) if len(filtered_metrics['mse']) > 0 else float('nan'),
            'std_mse': np.std(filtered_metrics['mse']) if len(filtered_metrics['mse']) > 0 else float('nan'),
            'min_mse': np.min(filtered_metrics['mse']) if len(filtered_metrics['mse']) > 0 else float('nan'),
            'max_mse': np.max(filtered_metrics['mse']) if len(filtered_metrics['mse']) > 0 else float('nan'),
            
            'avg_ade': np.mean(filtered_metrics['ade']) if len(filtered_metrics['ade']) > 0 else float('nan'),
            'std_ade': np.std(filtered_metrics['ade']) if len(filtered_metrics['ade']) > 0 else float('nan'),
            'min_ade': np.min(filtered_metrics['ade']) if len(filtered_metrics['ade']) > 0 else float('nan'),
            'max_ade': np.max(filtered_metrics['ade']) if len(filtered_metrics['ade']) > 0 else float('nan'),
            
            'avg_fde': np.mean(filtered_metrics['fde']) if len(filtered_metrics['fde']) > 0 else float('nan'),
            'std_fde': np.std(filtered_metrics['fde']) if len(filtered_metrics['fde']) > 0 else float('nan'),
            'min_fde': np.min(filtered_metrics['fde']) if len(filtered_metrics['fde']) > 0 else float('nan'),
            'max_fde': np.max(filtered_metrics['fde']) if len(filtered_metrics['fde']) > 0 else float('nan'),
            
            'avg_mr_2m': np.mean(filtered_metrics['mr_2m']) if len(filtered_metrics['mr_2m']) > 0 else float('nan'),
            'std_mr_2m': np.std(filtered_metrics['mr_2m']) if len(filtered_metrics['mr_2m']) > 0 else float('nan'),
            
            'avg_acc_kl': np.mean(filtered_metrics['acc_kl']) if len(filtered_metrics['acc_kl']) > 0 else float('nan'),
            'std_acc_kl': np.std(filtered_metrics['acc_kl']) if len(filtered_metrics['acc_kl']) > 0 else float('nan'),
            'min_acc_kl': np.min(filtered_metrics['acc_kl']) if len(filtered_metrics['acc_kl']) > 0 else float('nan'),
            'max_acc_kl': np.max(filtered_metrics['acc_kl']) if len(filtered_metrics['acc_kl']) > 0 else float('nan'),
            'avg_curv_kl': np.mean(filtered_metrics['curv_kl']) if len(filtered_metrics['curv_kl']) > 0 else float('nan'),
            'std_curv_kl': np.std(filtered_metrics['curv_kl']) if len(filtered_metrics['curv_kl']) > 0 else float('nan'),
            'min_curv_kl': np.min(filtered_metrics['curv_kl']) if len(filtered_metrics['curv_kl']) > 0 else float('nan'),
            'max_curv_kl': np.max(filtered_metrics['curv_kl']) if len(filtered_metrics['curv_kl']) > 0 else float('nan'),
            
            'mse_pass_rate': np.mean(np.array(filtered_metrics['mse']) <= self.max_mse_threshold) if len(filtered_metrics['mse']) > 0 else 0.0,
            'ade_pass_rate': np.mean(np.array(filtered_metrics['ade']) <= 0.5) if len(filtered_metrics['ade']) > 0 else 0.0,  # ä½¿ç”¨ 0.5m ä½œä¸º ADE é˜ˆå€¼
            'acc_kl_pass_rate': np.mean(np.array(filtered_metrics['acc_kl']) <= self.max_kl_divergence) if len(filtered_metrics['acc_kl']) > 0 else 0.0,
            'curv_kl_pass_rate': np.mean(np.array(filtered_metrics['curv_kl']) <= self.max_kl_divergence) if len(filtered_metrics['curv_kl']) > 0 else 0.0,
            'kl_pass_rate': np.mean([
                np.mean(np.array(filtered_metrics['acc_kl']) <= self.max_kl_divergence) if len(filtered_metrics['acc_kl']) > 0 else 0.0,
                np.mean(np.array(filtered_metrics['curv_kl']) <= self.max_kl_divergence) if len(filtered_metrics['curv_kl']) > 0 else 0.0
            ]),
            'total_scenes': total_scenes,
            'valid_mse_scenes': len(all_metrics['mse']),
            'filtered_mse_scenes': len(filtered_metrics['mse']),
            'valid_kl_scenes': min(len(all_metrics['acc_kl']), len(all_metrics['curv_kl'])),
            'filtered_kl_scenes': min(len(filtered_metrics['acc_kl']), len(filtered_metrics['curv_kl'])),
            'scene_details': scene_details,
            'outlier_info': outlier_info,
            'filtering_enabled': self.filter_outliers
        }
        
        return results


def main():
    parser = argparse.ArgumentParser(
        description="è¯„ä¼° STRIVE CVAE æ¨¡å‹ (traffic_model.pth) çš„è½¨è¿¹ç”Ÿæˆè´¨é‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬è¯„ä¼°ï¼ˆä½¿ç”¨éªŒè¯é›†ï¼‰
  python evaluate_traffic_model_cvae.py \\
      --ckpt model_ckpt/traffic_model.pth \\
      --data_dir data/nuscenes
  
  # è¯„ä¼°æŒ‡å®šæ•°é‡çš„åœºæ™¯
  python evaluate_traffic_model_cvae.py \\
      --ckpt model_ckpt/traffic_model.pth \\
      --data_dir data/nuscenes \\
      --num_samples 500
  
  # ä½¿ç”¨è‡ªå®šä¹‰é˜ˆå€¼
  python evaluate_traffic_model_cvae.py \\
      --ckpt model_ckpt/traffic_model.pth \\
      --data_dir data/nuscenes \\
      --max_mse 0.05 \\
      --max_kl 0.5
        """
    )
    
    parser.add_argument(
        "--ckpt",
        required=True,
        help="è®­ç»ƒå¥½çš„ traffic_model.pth è·¯å¾„"
    )
    
    parser.add_argument(
        "--data_dir",
        required=True,
        help="nuScenes æ•°æ®é›†ç›®å½•è·¯å¾„"
    )
    
    parser.add_argument(
        "--data_version",
        default="trainval",
        help="æ•°æ®é›†ç‰ˆæœ¬ï¼ˆé»˜è®¤ï¼štrainvalï¼‰"
    )
    
    parser.add_argument(
        "--split",
        default="val",
        choices=['train', 'val', 'test'],
        help="ä½¿ç”¨å“ªä¸ªæ•°æ®é›†åˆ†å‰²ï¼ˆé»˜è®¤ï¼švalï¼‰"
    )
    
    parser.add_argument(
        "--num_samples",
        type=int,
        default=None,
        help="è¯„ä¼°çš„åœºæ™¯æ•°é‡ï¼ˆé»˜è®¤ï¼šå…¨éƒ¨ï¼‰"
    )
    
    parser.add_argument(
        "--max_mse",
        type=float,
        default=0.05,
        help="MSE é˜ˆå€¼ (mÂ²)ï¼Œé»˜è®¤: 0.05"
    )
    
    parser.add_argument(
        "--max_kl",
        type=float,
        default=0.5,
        help="KL æ•£åº¦é˜ˆå€¼ï¼Œé»˜è®¤: 0.5"
    )
    
    parser.add_argument(
        "--out",
        default="./out/cvae_evaluation",
        help="è¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--no_filter_outliers",
        action="store_true",
        help="ä¸è¿‡æ»¤å¼‚å¸¸å€¼ï¼ˆé»˜è®¤ä¼šè¿‡æ»¤ï¼‰"
    )
    
    parser.add_argument(
        "--outlier_iqr_factor",
        type=float,
        default=1.5,
        help="IQR å¼‚å¸¸å€¼æ£€æµ‹å› å­ï¼ˆé»˜è®¤ï¼š1.5ï¼Œæ›´å¤§=æ›´å®½æ¾ï¼‰"
    )
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºè¯„ä¼°é…ç½®
    console.print(Panel.fit(
        f"[bold cyan]STRIVE CVAE æ¨¡å‹è´¨é‡è¯„ä¼°[/bold cyan]\n\n"
        f"[yellow]æ¨¡å‹è·¯å¾„:[/yellow] {args.ckpt}\n"
        f"[yellow]æ•°æ®é›†:[/yellow] {args.data_dir} ({args.split} split)\n"
        f"[yellow]è¯„ä¼°æ–¹æ³•:[/yellow] ä½¿ç”¨åéªŒå‡å€¼é‡å»º (model.reconstruct)\n\n"
        f"[green]è´¨é‡é˜ˆå€¼:[/green]\n"
        f"  â€¢ è½¨è¿¹ MSE: â‰¤ {args.max_mse} mÂ²\n"
        f"  â€¢ åŠ é€Ÿåº¦ KL æ•£åº¦: â‰¤ {args.max_kl}\n"
        f"  â€¢ æ›²ç‡ KL æ•£åº¦: â‰¤ {args.max_kl}",
        title="é…ç½®ä¿¡æ¯",
        border_style="cyan"
    ))
    
    # è®¾å¤‡è®¾ç½®
    device = get_device()
    console.print(f"[dim]ä½¿ç”¨è®¾å¤‡: {device}[/dim]\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.out, exist_ok=True)
    log_path = os.path.join(args.out, 'evaluation_log.txt')
    Logger.init(log_path)
    Logger.log(f'å¼€å§‹ CVAE æ¨¡å‹è¯„ä¼°: {args.ckpt}')
    
    # åŠ è½½æ•°æ®é›†å’Œåœ°å›¾
    console.print("[cyan]åŠ è½½æ•°æ®é›†å’Œåœ°å›¾ç¯å¢ƒ...[/cyan]")
    
    data_path = os.path.join(args.data_dir, args.data_version)
    
    # é»˜è®¤é…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    cfg = dict2obj({
        'past_len': 4,
        'future_len': 12,
        'map_obs_size_pix': 256,
        'map_obs_bounds': [-17.0, -38.5, 60.0, 38.5],
        'map_layers': ['drivable_area', 'carpark_area', 'road_divider', 'lane_divider'],
        'agent_types': ['car', 'truck'],
        'reduce_cats': False,
        'map_feat_size': 64,
        'past_feat_size': 64,
        'future_feat_size': 64,
        'latent_size': 32,
        'model_output_bicycle': True,
        'conv_kernel_list': [7, 5, 5, 3, 3, 3],
        'conv_stride_list': [2, 2, 2, 2, 2, 2],
        'conv_filter_list': [16, 32, 64, 64, 128, 128]
    })
    
    map_env = NuScenesMapEnv(
        data_path,
        bounds=cfg.map_obs_bounds,
        L=cfg.map_obs_size_pix,
        W=cfg.map_obs_size_pix,
        layers=cfg.map_layers,
        device=device
    )
    
    test_dataset = NuScenesDataset(
        data_path,
        map_env,
        version=args.data_version,
        split=args.split,
        categories=cfg.agent_types,
        npast=cfg.past_len,
        nfuture=cfg.future_len,
        reduce_cats=cfg.reduce_cats
    )
    
    console.print(f"[green]âœ“ æ•°æ®é›†åŠ è½½å®Œæˆ: {len(test_dataset)} ä¸ªåœºæ™¯[/green]")
    
    # åˆ›å»ºæ¨¡å‹
    console.print("[cyan]åˆ›å»ºæ¨¡å‹...[/cyan]")
    model = TrafficModel(
        cfg.past_len, cfg.future_len, cfg.map_obs_size_pix, len(test_dataset.categories),
        map_feat_size=cfg.map_feat_size,
        past_feat_size=cfg.past_feat_size,
        future_feat_size=cfg.future_feat_size,
        latent_size=cfg.latent_size,
        output_bicycle=cfg.model_output_bicycle,
        conv_channel_in=map_env.num_layers,
        conv_kernel_list=cfg.conv_kernel_list,
        conv_stride_list=cfg.conv_stride_list,
        conv_filter_list=cfg.conv_filter_list
    ).to(device)
    
    # åŠ è½½æ¨¡å‹æƒé‡
    ckpt_epoch, _ = load_state(args.ckpt, model, map_location=device)
    Logger.log(f'åŠ è½½æ¨¡å‹æƒé‡ (epoch {ckpt_epoch})')
    console.print(f"[green]âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (epoch {ckpt_epoch})[/green]")
    console.print(f"[dim]æ¨¡å‹å‚æ•°æ•°é‡: {count_params(model):,}[/dim]\n")
    
    # è®¾ç½®å½’ä¸€åŒ–å™¨
    model.set_normalizer(test_dataset.get_state_normalizer())
    model.set_att_normalizer(test_dataset.get_att_normalizer())
    if cfg.model_output_bicycle:
        from datasets.utils import NUSC_BIKE_PARAMS
        model.set_bicycle_params(NUSC_BIKE_PARAMS)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = CVAEModelEvaluator(
        model=model,
        test_dataset=test_dataset,
        map_env=map_env,
        device=device,
        max_mse_threshold=args.max_mse,
        max_kl_divergence=args.max_kl,
        filter_outliers=not args.no_filter_outliers,
        outlier_iqr_factor=args.outlier_iqr_factor
    )
    
    # æ‰§è¡Œè¯„ä¼°
    start_time = time.time()
    results = evaluator.evaluate_dataset(num_samples=args.num_samples)
    eval_time = time.time() - start_time
    
    # æ‰“å°ç»“æœ
    console.print("\n" + "="*70)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆç»“æœ
    has_valid_mse = not np.isnan(results['avg_mse'])
    has_valid_ade = not np.isnan(results['avg_ade'])
    has_valid_fde = not np.isnan(results['avg_fde'])
    has_valid_mr = not np.isnan(results['avg_mr_2m'])
    has_valid_acc_kl = not np.isnan(results['avg_acc_kl'])
    has_valid_curv_kl = not np.isnan(results['avg_curv_kl'])
    
    # åˆ¤æ–­æ˜¯å¦é€šè¿‡ï¼ˆåªéœ€è¦æ»¡è¶³é˜ˆå€¼ï¼‰
    mse_pass = has_valid_mse and results['avg_mse'] <= args.max_mse
    ade_pass = has_valid_ade and results['avg_ade'] <= 0.5  # ADE é˜ˆå€¼ 0.5m
    acc_kl_pass = has_valid_acc_kl and results['avg_acc_kl'] <= args.max_kl
    curv_kl_pass = has_valid_curv_kl and results['avg_curv_kl'] <= args.max_kl
    
    # æ ¼å¼åŒ–è¾“å‡º
    if has_valid_mse:
        mse_avg_str = f"{results['avg_mse']:.6f} mÂ²"
        mse_min_str = f"{results['min_mse']:.6f} mÂ²"
        mse_max_str = f"{results['max_mse']:.6f} mÂ²"
        mse_status = "âœ… é€šè¿‡" if mse_pass else "âŒ æœªé€šè¿‡"
    else:
        mse_avg_str = "N/A"
        mse_min_str = "N/A"
        mse_max_str = "N/A"
        mse_status = "N/A"
    
    if has_valid_acc_kl:
        acc_kl_avg_str = f"{results['avg_acc_kl']:.6f}"
        acc_kl_min_str = f"{results['min_acc_kl']:.6f}"
        acc_kl_max_str = f"{results['max_acc_kl']:.6f}"
        acc_kl_status = "âœ… é€šè¿‡" if acc_kl_pass else "âŒ æœªé€šè¿‡"
    else:
        acc_kl_avg_str = "N/A"
        acc_kl_min_str = "N/A"
        acc_kl_max_str = "N/A"
        acc_kl_status = "N/A"
    
    if has_valid_curv_kl:
        curv_kl_avg_str = f"{results['avg_curv_kl']:.6f}"
        curv_kl_min_str = f"{results['min_curv_kl']:.6f}"
        curv_kl_max_str = f"{results['max_curv_kl']:.6f}"
        curv_kl_status = "âœ… é€šè¿‡" if curv_kl_pass else "âŒ æœªé€šè¿‡"
    else:
        curv_kl_avg_str = "N/A"
        curv_kl_min_str = "N/A"
        curv_kl_max_str = "N/A"
        curv_kl_status = "N/A"
    
    # å‡†å¤‡ç»Ÿè®¡ä¿¡æ¯
    filtering_info = ""
    if results.get('filtering_enabled', False):
        filtering_info = (
            f"\n[dim]å¼‚å¸¸å€¼è¿‡æ»¤: "
            f"MSE ç§»é™¤ {results['outlier_info'].get('mse_outlier_count', 0)} ä¸ª, "
            f"åŠ é€Ÿåº¦ KL ç§»é™¤ {results['outlier_info'].get('acc_kl_outlier_count', 0)} ä¸ª, "
            f"æ›²ç‡ KL ç§»é™¤ {results['outlier_info'].get('curv_kl_outlier_count', 0)} ä¸ª[/dim]"
        )
        
        # æ˜¾ç¤ºåŸå§‹å¹³å‡å€¼å¯¹æ¯”
        if has_valid_mse and not np.isnan(results.get('raw_avg_mse', float('nan'))):
            filtering_info += f"\n[dim]åŸå§‹ MSE å¹³å‡å€¼ï¼ˆå«å¼‚å¸¸å€¼ï¼‰: {results['raw_avg_mse']:.6f} mÂ²[/dim]"
    
    console.print(Panel.fit(
        f"[bold yellow]CVAE æ¨¡å‹è´¨é‡è¯„ä¼°ç»“æœ[/bold yellow]"
        f"{' [è¿‡æ»¤å¼‚å¸¸å€¼å]' if results.get('filtering_enabled', False) else ''}\n\n"
        f"[cyan]1. è½¨è¿¹é‡å»º MSE:[/cyan]\n"
        f"   å¹³å‡å€¼: [bold]{mse_avg_str}[/bold]  |  æœ€å°å€¼: [bold green]{mse_min_str}[/bold green]  |  æœ€å¤§å€¼: {mse_max_str}\n"
        f"   é˜ˆå€¼: â‰¤ {args.max_mse} mÂ²  |  ç»“æœ: [bold]{mse_status}[/bold]\n\n"
        f"[cyan]2. åŠ é€Ÿåº¦åˆ†å¸ƒ KL æ•£åº¦:[/cyan]\n"
        f"   å¹³å‡å€¼: [bold]{acc_kl_avg_str}[/bold]  |  æœ€å°å€¼: [bold green]{acc_kl_min_str}[/bold green]  |  æœ€å¤§å€¼: {acc_kl_max_str}\n"
        f"   é˜ˆå€¼: â‰¤ {args.max_kl}  |  ç»“æœ: [bold]{acc_kl_status}[/bold]\n\n"
        f"[cyan]3. æ›²ç‡åˆ†å¸ƒ KL æ•£åº¦:[/cyan]\n"
        f"   å¹³å‡å€¼: [bold]{curv_kl_avg_str}[/bold]  |  æœ€å°å€¼: [bold green]{curv_kl_min_str}[/bold green]  |  æœ€å¤§å€¼: {curv_kl_max_str}\n"
        f"   é˜ˆå€¼: â‰¤ {args.max_kl}  |  ç»“æœ: [bold]{curv_kl_status}[/bold]\n\n"
        f"[cyan]è¯„ä¼°ç»Ÿè®¡:[/cyan]\n"
        f"   æ€»åœºæ™¯æ•°: {results['total_scenes']} | "
        f"æœ‰æ•ˆ MSE: {results.get('valid_mse_scenes', 0)} â†’ è¿‡æ»¤å: {results.get('filtered_mse_scenes', 0)} | "
        f"æœ‰æ•ˆ KL: {results.get('valid_kl_scenes', 0)} â†’ è¿‡æ»¤å: {results.get('filtered_kl_scenes', 0)}\n"
        f"   è¯„ä¼°ç”¨æ—¶: {eval_time:.2f} ç§’"
        f"{filtering_info}",
        title="ğŸ“Š è¯„ä¼°ç»“æœ",
        border_style="green" if (mse_pass and acc_kl_pass and curv_kl_pass) else "yellow"
    ))
    
    # ä¿å­˜ç»“æœ
    results_file = os.path.join(args.out, 'evaluation_results.txt')
    with open(results_file, 'w') as f:
        f.write(f"CVAE Model Evaluation Results\n")
        f.write(f"="*50 + "\n\n")
        f.write(f"Model: {args.ckpt}\n")
        f.write(f"Dataset: {args.data_dir} ({args.split})\n")
        f.write(f"Total scenes: {results['total_scenes']}\n")
        f.write(f"Valid MSE scenes: {results.get('valid_mse_scenes', 0)}\n")
        f.write(f"Filtered MSE scenes: {results.get('filtered_mse_scenes', 0)}\n")
        f.write(f"Valid KL scenes: {results.get('valid_kl_scenes', 0)}\n")
        f.write(f"Filtered KL scenes: {results.get('filtered_kl_scenes', 0)}\n")
        f.write(f"Outlier filtering: {'Enabled' if results.get('filtering_enabled', False) else 'Disabled'}\n\n")
        
        if results.get('filtering_enabled', False) and 'outlier_info' in results:
            f.write(f"Outliers Removed:\n")
            f.write(f"  MSE: {results['outlier_info'].get('mse_outlier_count', 0)}\n")
            f.write(f"  Acceleration KL: {results['outlier_info'].get('acc_kl_outlier_count', 0)}\n")
            f.write(f"  Curvature KL: {results['outlier_info'].get('curv_kl_outlier_count', 0)}\n\n")
            
            if not np.isnan(results.get('raw_avg_mse', float('nan'))):
                f.write(f"Original MSE (with outliers): {results['raw_avg_mse']:.6f} mÂ²\n")
                f.write(f"Filtered MSE (without outliers): {results['avg_mse']:.6f} mÂ²\n\n")
        
        f.write(f"Results:\n")
        f.write(f"-" * 50 + "\n")
        if has_valid_mse:
            f.write(f"1. Trajectory MSE (threshold: â‰¤ {args.max_mse} mÂ²)\n")
            f.write(f"   Average: {results['avg_mse']:.6f} mÂ²\n")
            f.write(f"   Minimum: {results['min_mse']:.6f} mÂ² (best case)\n")
            f.write(f"   Maximum: {results['max_mse']:.6f} mÂ²\n")
            f.write(f"   Status: {'PASS' if mse_pass else 'FAIL'}\n\n")
        else:
            f.write(f"1. Trajectory MSE: N/A\n\n")
        
        if has_valid_acc_kl:
            f.write(f"2. Acceleration KL Divergence (threshold: â‰¤ {args.max_kl})\n")
            f.write(f"   Average: {results['avg_acc_kl']:.6f}\n")
            f.write(f"   Minimum: {results['min_acc_kl']:.6f} (best case)\n")
            f.write(f"   Maximum: {results['max_acc_kl']:.6f}\n")
            f.write(f"   Status: {'PASS' if acc_kl_pass else 'FAIL'}\n\n")
        else:
            f.write(f"2. Acceleration KL Divergence: N/A\n\n")
        
        if has_valid_curv_kl:
            f.write(f"3. Curvature KL Divergence (threshold: â‰¤ {args.max_kl})\n")
            f.write(f"   Average: {results['avg_curv_kl']:.6f}\n")
            f.write(f"   Minimum: {results['min_curv_kl']:.6f} (best case)\n")
            f.write(f"   Maximum: {results['max_curv_kl']:.6f}\n")
            f.write(f"   Status: {'PASS' if curv_kl_pass else 'FAIL'}\n\n")
        else:
            f.write(f"3. Curvature KL Divergence: N/A\n\n")
        
        f.write(f"-" * 50 + "\n")
        if mse_pass and acc_kl_pass and curv_kl_pass:
            f.write(f"Overall: ALL METRICS PASS\n")
        else:
            f.write(f"Overall: SOME METRICS FAIL\n")
    
    console.print(f"\n[green]âœ“ ç»“æœå·²ä¿å­˜åˆ°: {results_file}[/green]")
    
    # ä¿å­˜è¯¦ç»†åœºæ™¯ç»“æœåˆ°CSV
    if 'scene_details' in results and len(results['scene_details']) > 0:
        import pandas as pd
        csv_file = os.path.join(args.out, 'scene_details.csv')
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(results['scene_details'])
        
        # æŒ‰MSEæ’åºï¼ˆæ–¹ä¾¿æŸ¥çœ‹æœ€å·®çš„åœºæ™¯ï¼‰
        if 'mse' in df.columns:
            df = df.sort_values('mse', ascending=False, na_position='last')
        
        # ä¿å­˜CSV
        df.to_csv(csv_file, index=False, float_format='%.6f')
        console.print(f"[green]âœ“ è¯¦ç»†åœºæ™¯ç»“æœå·²ä¿å­˜åˆ°: {csv_file}[/green]")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if has_valid_mse:
            console.print(f"\n[cyan]åœºæ™¯ç»Ÿè®¡åˆ†æ:[/cyan]")
            console.print(f"  â€¢ MSE > 1.0 mÂ² çš„åœºæ™¯æ•°: {len(df[df['mse'] > 1.0])} / {len(df[df['mse'].notna()])}")
            console.print(f"  â€¢ MSE > 0.5 mÂ² çš„åœºæ™¯æ•°: {len(df[df['mse'] > 0.5])} / {len(df[df['mse'].notna()])}")
            console.print(f"  â€¢ MSE > 0.1 mÂ² çš„åœºæ™¯æ•°: {len(df[df['mse'] > 0.1])} / {len(df[df['mse'].notna()])}")
            console.print(f"  â€¢ MSE â‰¤ 0.05 mÂ² (é€šè¿‡) çš„åœºæ™¯æ•°: {len(df[df['mse'] <= 0.05])} / {len(df[df['mse'].notna()])}")
            
            # æ˜¾ç¤ºæœ€å·®çš„5ä¸ªåœºæ™¯
            worst_scenes = df[df['mse'].notna()].head(5)
            if len(worst_scenes) > 0:
                console.print(f"\n[yellow]MSE æœ€é«˜çš„ 5 ä¸ªåœºæ™¯:[/yellow]")
                from rich.table import Table
                table = Table(show_header=True, header_style="bold magenta")
                table.add_column("åœºæ™¯ID", justify="right", style="cyan")
                table.add_column("MSE (mÂ²)", justify="right", style="red")
                table.add_column("åŠ é€Ÿåº¦KL", justify="right")
                table.add_column("æ›²ç‡KL", justify="right")
                table.add_column("è½¦è¾†æ•°", justify="right")
                
                for _, row in worst_scenes.iterrows():
                    table.add_row(
                        str(row['scene_id']),
                        f"{row['mse']:.6f}" if pd.notna(row['mse']) else "N/A",
                        f"{row['acc_kl']:.6f}" if pd.notna(row['acc_kl']) else "N/A",
                        f"{row['curv_kl']:.6f}" if pd.notna(row['curv_kl']) else "N/A",
                        str(row['num_agents'])
                    )
                console.print(table)
    
    Logger.log(f'è¯„ä¼°å®Œæˆï¼Œç”¨æ—¶ {eval_time:.2f} ç§’')
    
    # è¿”å›çŠ¶æ€ç 
    if mse_pass and acc_kl_pass and curv_kl_pass:
        console.print("\n[bold green]ğŸ‰ CVAE æ¨¡å‹æ»¡è¶³æ‰€æœ‰è´¨é‡æŒ‡æ ‡è¦æ±‚ï¼[/bold green]\n")
        return 0
    else:
        console.print("\n[bold yellow]âš ï¸ CVAE æ¨¡å‹æœªèƒ½æ»¡è¶³æ‰€æœ‰è´¨é‡æŒ‡æ ‡[/bold yellow]\n")
        return 1


if __name__ == "__main__":
    sys.exit(main())

